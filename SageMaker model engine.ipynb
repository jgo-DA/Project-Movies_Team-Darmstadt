{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The files have been generated in Databricks and provided on the S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install boto3 # not required for Jupyter Notebooks on AWS infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Session(region_name='eu-central-1')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "boto_session = boto3.Session() # Grabs session details directly from aws configuration in EC2 instance running the Notebook server\n",
    "boto_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket 's3://sjf-project/'.\n"
     ]
    }
   ],
   "source": [
    "# Define variables for paths\n",
    "s3_path = f\"s3://sjf-project/\"\n",
    "output_path = s3_path + \"estimator\"\n",
    "\n",
    "print(f\"Using bucket '{s3_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sagemaker\n",
    "import sagemaker\n",
    "\n",
    "# Create a SageMaker Session\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto_session)\n",
    "\n",
    "#The following IAM role ARN was taken from the flutz notebook listed in the SageMaker console:\n",
    "sm_execution_role = 'arn:aws:iam::898627427171:role/service-role/AmazonSageMaker-ExecutionRole-20201106T104926'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select cells for either XGBooster or Linear Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use a previously-built, AWS XGBoost model for training\n",
    "\n",
    "# from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "# # container = get_image_uri(***insert correct arguments here***) \n",
    "\n",
    "# container = get_image_uri(region_name=boto_session.region_name,\n",
    "#                           repo_name='xgboost',\n",
    "#                           repo_version='1.0-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# Use the predefined Linear learner model\n",
    "\n",
    "\n",
    "ecr_path = \"664544806723.dkr.ecr.eu-central-1.amazonaws.com\"\n",
    "\n",
    "linear = sagemaker.estimator.Estimator(f\"{ecr_path}/linear-learner:latest\",\n",
    "                              sm_execution_role,\n",
    "                              train_instance_count=1,\n",
    "                              train_instance_type=\"ml.m5.xlarge\",\n",
    "                              output_path=output_path,\n",
    "                              sagemaker_session=sagemaker.Session(),\n",
    "                              base_job_name=\"sjf-linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # From https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html \n",
    "# # XGBoost ecr path is: 492215442770.dkr.ecr.eu-central-1.amazonaws.com\n",
    "# ecr_path = '492215442770.dkr.ecr.eu-central-1.amazonaws.com'\n",
    "\n",
    "# #'ml.m4.xlarge') | 'ml.t2.medium' || train_instance_type= \"ml.m5.large\" -> \"ml.m5.xlarge\"\n",
    "# #Instance Name\tvCPU\tECU\tRAM   \tInstance-GB\tLinux/UNIX-Nutzung\n",
    "# #t2.medium\t2\tVar.\t4 GiB\tNur EBS \t0,0536 USD pro Stunde\n",
    "# #m4.xlarge\t4\t13\t16 GiB\tNur EBS \t0,24 USD pro Stunde\n",
    "# #m5.large\t2\t10\t8 GiB\tNur EBS \t0,115 USD pro Stunde\n",
    "# #m5.xlarge\t4\t16\t16 GiB\tNur EBS \t0,23 USD pro Stunde\n",
    "# xgboost = sagemaker.estimator.Estimator(f\"{ecr_path}/sagemaker-xgboost:1.0-1-cpu-py3\",\n",
    "#                               sm_execution_role,\n",
    "#                               train_instance_count=1,\n",
    "#                               train_instance_type=\"ml.m5.xlarge\",\n",
    "#                               output_path=output_path,\n",
    "#                               sagemaker_session=sagemaker_session,\n",
    "#                               base_job_name=\"sjf-xgboost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# Create pointers to the S3 train and test datasets\n",
    "\n",
    "from sagemaker.session import s3_input\n",
    "\n",
    "Train = 'train_data_trial.csv'\n",
    "Valid = 'valid_data_trial.csv'\n",
    "\n",
    "s3_input_train = sagemaker.session.s3_input(s3_data=f\"{s3_path}{Train}\", content_type=\"text/csv\")\n",
    "s3_input_valid = sagemaker.session.s3_input(s3_data=f\"{s3_path}{Valid}\", content_type=\"text/csv\")\n",
    "#s3_input_train = sagemaker.session.s3_input(s3_data=f\"{s3_path}train_sample.csv\", content_type=\"text/csv\")\n",
    "#s3_input_valid = sagemaker.session.s3_input(s3_data=f\"{s3_path}valid_sample.csv\", content_type=\"text/csv\")\n",
    "#s3_input_test = sagemaker.session.s3_input(s3_data=f\"{s3_path}test.csv\", content_type=\"text/csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select cells for XGBooster or linear learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an XGBoost Estimator\n",
    "\n",
    "# # From https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html \n",
    "# # XGBoost ecr path is: 492215442770.dkr.ecr.eu-central-1.amazonaws.com\n",
    "# ecr_path = '492215442770.dkr.ecr.eu-central-1.amazonaws.com'\n",
    "\n",
    "# #'ml.m4.xlarge') | 'ml.t2.medium' || train_instance_type= \"ml.m5.large\" -> \"ml.m5.xlarge\"\n",
    "# #Instance Name\tvCPU\tECU\tRAM   \tInstance-GB\tLinux/UNIX-Nutzung\n",
    "# #t2.medium\t2\tVar.\t4 GiB\tNur EBS \t0,0536 USD pro Stunde\n",
    "# #m4.xlarge\t4\t13\t16 GiB\tNur EBS \t0,24 USD pro Stunde\n",
    "# #m5.large\t2\t10\t8 GiB\tNur EBS \t0,115 USD pro Stunde\n",
    "# #m5.xlarge\t4\t16\t16 GiB\tNur EBS \t0,23 USD pro Stunde\n",
    "# xgboost = sagemaker.estimator.Estimator(f\"{ecr_path}/sagemaker-xgboost:1.0-1-cpu-py3\",\n",
    "#                               sm_execution_role,\n",
    "#                               train_instance_count=1,\n",
    "#                               train_instance_type=\"ml.m5.xlarge\",\n",
    "#                               output_path=output_path,\n",
    "#                               sagemaker_session=sagemaker_session,\n",
    "#                               base_job_name=\"sjf-xgboost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select the your specific hyperparameters (Optional)\n",
    "\n",
    "# # From https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html\n",
    "\n",
    "# xgboost.set_hyperparameters(\n",
    "#     eta=0.3,                         # default 0.3 range 0 - 1   \n",
    "#     num_round=30,                    # required | valid values: int | The number of rounds to run the training.\n",
    "#     objective = 'reg:linear'  # Examples: reg:linear, reg:logistic, multi:softmax, reg:squarederror [default] \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the your specific hyperparameters (Optional) - from Live Coding\n",
    "linear.set_hyperparameters(\n",
    "    predictor_type=\"regressor\",\n",
    "    normalize_data=False,\n",
    "    mini_batch_size=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-19 15:08:51 Starting - Starting the training job...\n",
      "2020-11-19 15:08:55 Starting - Launching requested ML instances......\n",
      "2020-11-19 15:10:04 Starting - Preparing the instances for training...\n",
      "2020-11-19 15:10:38 Downloading - Downloading input data...\n",
      "2020-11-19 15:11:21 Training - Training image download completed. Training in progress.\n",
      "2020-11-19 15:11:21 Uploading - Uploading generated training model\n",
      "2020-11-19 15:11:21 Failed - Training job failed\n",
      ".\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[11/19/2020 15:11:16 INFO 139671278114624] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'loss_insensitivity': u'0.01', u'epochs': u'15', u'feature_dim': u'auto', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'true', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'1000', u'huber_delta': u'1.0', u'num_classes': u'1', u'beta_1': u'auto', u'loss': u'auto', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[34m[11/19/2020 15:11:16 INFO 139671278114624] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'normalize_data': u'False', u'mini_batch_size': u'50', u'predictor_type': u'regressor'}\u001b[0m\n",
      "\u001b[34m[11/19/2020 15:11:16 INFO 139671278114624] Final configuration: {u'loss_insensitivity': u'0.01', u'epochs': u'15', u'feature_dim': u'auto', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'False', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'50', u'huber_delta': u'1.0', u'num_classes': u'1', u'predictor_type': u'regressor', u'beta_1': u'auto', u'loss': u'auto', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[34m[11/19/2020 15:11:16 WARNING 139671278114624] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[11/19/2020 15:11:16 INFO 139671278114624] Using default worker.\u001b[0m\n",
      "\u001b[34m[11/19/2020 15:11:16 INFO 139671278114624] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[11/19/2020 15:11:16 INFO 139671278114624] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 147, \"sum\": 147.0, \"min\": 147}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 147, \"sum\": 147.0, \"min\": 147}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 7350, \"sum\": 7350.0, \"min\": 7350}, \"Total Batches Seen\": {\"count\": 1, \"max\": 148, \"sum\": 148.0, \"min\": 148}, \"Total Records Seen\": {\"count\": 1, \"max\": 7400, \"sum\": 7400.0, \"min\": 7400}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 7350, \"sum\": 7350.0, \"min\": 7350}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1605798678.343131, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1605798678.343103}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/19/2020 15:11:18 ERROR 139671278114624] Customer Error: Found at least 1 entries in file /opt/ml/input/data/train/train_data_trial.csv with missing values:\u001b[0m\n",
      "\u001b[34mRow 7393, column 5\u001b[0m\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job sjf-linear-2020-11-19-15-08-51-231: Failed. Reason: ClientError: Found at least 1 entries in file /opt/ml/input/data/train/train_data_trial.csv with missing values:\nRow 7393, column 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-0e06f5aefbdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#xgboost.fit({\"train\": s3_input_train})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms3_input_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3076\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3077\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3078\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   2669\u001b[0m                 ),\n\u001b[1;32m   2670\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2672\u001b[0m             )\n\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job sjf-linear-2020-11-19-15-08-51-231: Failed. Reason: ClientError: Found at least 1 entries in file /opt/ml/input/data/train/train_data_trial.csv with missing values:\nRow 7393, column 5"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "#xgboost.fit({\"train\": s3_input_train})\n",
    "linear.fit({\"train\": s3_input_train})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy your model to an endpoint to perform predictions\n",
    "\n",
    "Predictor = linear.deploy(\n",
    "#Predictor = xgboost.deploy(\n",
    "    initial_instance_count = 1, \n",
    "    instance_type = 'ml.t2.medium')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictor.endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the predictor's serializer and deserializer\n",
    "\n",
    "from sagemaker.predictor import csv_serializer, csv_deserializer\n",
    "\n",
    "Predictor.serializer = csv_serializer\n",
    "Predictor.deserializer = csv_deserializer\n",
    "Predictor.content_type = \"text/csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictor.endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the validate dataset into a dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "validate_df = pd.read_csv(f\"{s3_path}{Valid}\", header=None)\n",
    "display(validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{s3_path}{Train}\", header=None)\n",
    "display(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df.iloc[0, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = Predictor.predict(validate_df.iloc[0:, 1:].values)\n",
    "#len(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_predicted = list(map(lambda pred: round(float(pred),1), prediction[0])) # prediction-Werte werde auf eine Kommastelle gerundet\n",
    "y_predicted = list(map(float, prediction[0]))\n",
    "display(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = validate_df[0].values\n",
    "display(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y_true, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "print(explained_variance_score(y_true, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y_true, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "print(mean_absolute_error(y_true, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=[]\n",
    "pred_df = pd.DataFrame(y_predicted, columns=['prediction'])\n",
    "pred_df['ground_truth']=y_true\n",
    "display(pred_df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = y_true\n",
    "y = y_predicted\n",
    "plt.scatter(x, y, color=\"red\")\n",
    "plt.title(\"IMDb Ratings Prediction Model 1840 rows & 409 columns\")\n",
    "plt.xlabel(\"y_true\")\n",
    "plt.ylabel(\"y_prediction\")\n",
    "plt.xlim([1,10])\n",
    "plt.ylim([1,10])\n",
    "plt.plot([1,10],[1,10], color=\"blue\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
